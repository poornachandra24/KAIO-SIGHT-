project_name: "KAIO-SIGHT Finetuning"

hub:
  hf_repo: "Thunderbird2410/KAIO-SIGHT"

model:
  base_model: "Qwen/Qwen2.5-VL-7B-Instruct"
  max_seq_length: 65536
  lora_rank: 64
  lora_alpha: 128
  # Resolution settings used inside trainer.py logic
  resolution: 1008 

training:
  # Batch Size Strategy for MI300X Stability
  # We force BS=1 in code to prevent broadcasting errors.
  # We use Grad Accumulation to reach the target effective batch size.
  batch_size: 8              # Keep 1 per device
  gradient_accumulation_steps: 2  # Effective Batch Size = 32
  
  # Optimization
  learning_rate: 1e-4
  optimizer: "paged_adamw_8bit"
  weight_decay: 0.01
  # Workers: Enable 8 CPU cores to prepare data in parallel
  dataloader_num_workers: 4 
  
  # Duration
  num_epochs: 1               # Set to 1 for the first production run; this covers the entire dataset.
  max_steps: -1               # -1 means "Run until num_epochs is finished"; else set a fixed number of steps.
  
  # Scheduling
  warmup_ratio: 0.1           # Warmup for 10% of total steps
  lr_scheduler_type: "cosine"  # Cosine learning rate decay
  
  # Logging & Saving
  logging_steps: 5            # Log loss every 5 steps
  save_steps: 50            # Save checkpoint every 500 steps (~45-60 mins)
  save_total_limit: 3         # Keep only the last 3 checkpoints to save disk space


vision:
  # Options: "4-cam" or "7-cam"
  camera_setup: "4-cam"
  window_size: 16
  # The loader will look at these keys based on camera_setup
  setups:
    4-cam:
      grid: [2, 2]
      cameras: 
        - "camera_front_wide_120fov"
        - "camera_front_tele_30fov"
        - "camera_rear_left_70fov"
        - "camera_rear_right_70fov"
    7-cam:
      grid: [3, 3]
      cameras:
        - "camera_front_wide_120fov"
        - "camera_front_tele_30fov"
        - "camera_cross_left_120fov"
        - "camera_cross_right_120fov"
        - "camera_rear_left_70fov"
        - "camera_rear_right_70fov"
        - "camera_rear_tele_30fov"
