# ðŸ§ª Inference Evaluation Workflow

This guide details the workflow for evaluating the performance of multiple HuggingFace model commits against ground truth egomotion data.

## Overview

The evaluation process involves:
1.  **Extracting Data**: Getting raw video and ground truth metrics for a specific sample UUID.
2.  **Iterating Commits**: Running inference on a list of specific model revisions.
3.  **Tracking**: Logging results to Comet ML with a specific project name.
4.  **Analysis**: Comparing model predictions (Displacement/Velocity) against ground truth and saving results.

## Scripts

### 1. `evaluate_commits.py`
**Location**: `src/inference/evaluate_commits.py`

This is the main driver script. It:
*   Defines the list of target Commit IDs.
*   Calculates ground truth (Displacement & Velocity) from `data/labels/egomotion`.
*   Iterates through each commit, launching `test_inference.py`.
*   Parses the raw text output to extract numerical predictions.
*   Captures **Comet ML Experiment Name** and **URL**.
*   Saves the aggregated results incrementally to a Parquet file.

**Key Variables**:
*   `UUID`: The sample UUID to test (Default: `402fdeb6-f078-44af-a9b3-79bfa15961a1`).
*   `COMMITS`: List of HuggingFace commit hashes.

**Usage**:
```bash
python src/inference/evaluate_commits.py
```

### 2. `test_inference.py`
**Location**: `src/inference/test_inference.py`

Updated to support strict output formatting and custom project logging.

**New Arguments**:
*   `--project_name`: Overrides the default Comet ML project name (Used: `kaio-sight-inference-test`).
*   `--track`: Enables Comet ML logging.
*   `--load_in_4bit`: Uses 4-bit quantization for faster inference.

**Prompting**:
The script uses a strict prompt to ensure the model outputs parsable metrics:
> "Analyze the {setup} sequence. Predict the ego-motion. Output ONLY the Displacement in meters and Velocity in m/s. Format: Displacement: <value> m, Velocity: <value> m/s"

## Output Data

The results are saved to:
`src/inference/evaluation_results.parquet`

**Schema**:
*   `commit_id`: HuggingFace Commit Hash.
*   `ground_truth_disp`: Actual displacement (m).
*   `ground_truth_vel`: Actual average velocity (m/s).
*   `pred_disp`: Model predicted displacement.
*   `pred_vel`: Model predicted velocity.
*   `error_disp`: Absolute error (Displacement).
*   `error_vel`: Absolute error (Velocity).
*   `raw_output`: The raw text string generated by the model.
*   `comet_experiment_name`: The human-readable Comet experiment name (e.g., `colossal_snail_6701`).
*   `comet_url`: Direct link to the Comet experiment.

  [Example Inference Results for multiple finetuning jobs
](https://docs.google.com/spreadsheets/d/1l8tN8nYn9vxs2DHJNHr9e9GqHWzsWYXKoo0vL4fwur0/edit?gid=668247664#gid=668247664)
